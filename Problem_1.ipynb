{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grzegorz/miniconda3/envs/gk_py/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt = 'data/zip_test.txt'\n",
    "train_txt = 'data/zip_train.txt'\n",
    "# train_raw = np.loadtxt(train_txt, delimiter=',', usecols=(0, 2), unpack=True)\n",
    "train_raw = np.loadtxt(train_txt)\n",
    "test_raw = np.loadtxt(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7291\n",
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "train_lab = train_raw[:, 0]\n",
    "train_raw = train_raw[:, 1:]\n",
    "\n",
    "test_lab = test_raw[:, 0]\n",
    "test_raw = test_raw[:, 1:]\n",
    "\n",
    "print(train_lab.size)\n",
    "print(train_raw[0].size)\n",
    "print(len(train_raw[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "train_mat = list()\n",
    "for ith in train_raw:\n",
    "    image = np.resize(ith,(16,16))\n",
    "    train_mat.append(image)\n",
    "train_mat = np.array(train_mat)\n",
    "\n",
    "test_mat = list()\n",
    "for ith in test_raw:\n",
    "    image = np.resize(ith,(16,16))\n",
    "    test_mat.append(image)\n",
    "test_mat = np.array(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "(7291, 16, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idn = 110\n",
    "print(train_lab[idn])\n",
    "mgplot = plt.imshow(train_mat[10])\n",
    "print(train_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lab\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "img_rows, img_cols = 16, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_raw[2][1:])\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 16\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = train_mat.reshape(train_mat.shape[0], img_rows, img_cols, 1)\n",
    "x_test = test_mat.reshape(test_mat.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(train_lab.astype('int'), num_classes)\n",
    "y_test = keras.utils.to_categorical(test_lab.astype('int'), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7291 samples, validate on 2007 samples\n",
      "Epoch 1/12\n",
      "7291/7291 [==============================] - 9s 1ms/step - loss: 0.7838 - acc: 0.7482 - val_loss: 0.3030 - val_acc: 0.9093\n",
      "Epoch 2/12\n",
      "7291/7291 [==============================] - 10s 1ms/step - loss: 0.2356 - acc: 0.9302 - val_loss: 0.2210 - val_acc: 0.9317\n",
      "Epoch 3/12\n",
      "7291/7291 [==============================] - 7s 943us/step - loss: 0.1429 - acc: 0.9561 - val_loss: 0.1961 - val_acc: 0.9412\n",
      "Epoch 4/12\n",
      "7291/7291 [==============================] - 7s 916us/step - loss: 0.1186 - acc: 0.9649 - val_loss: 0.1891 - val_acc: 0.9477\n",
      "Epoch 5/12\n",
      "7291/7291 [==============================] - 7s 937us/step - loss: 0.0911 - acc: 0.9738 - val_loss: 0.1729 - val_acc: 0.9517\n",
      "Epoch 6/12\n",
      "7291/7291 [==============================] - 7s 926us/step - loss: 0.0753 - acc: 0.9782 - val_loss: 0.1755 - val_acc: 0.9557\n",
      "Epoch 7/12\n",
      "7291/7291 [==============================] - 7s 973us/step - loss: 0.0646 - acc: 0.9793 - val_loss: 0.1638 - val_acc: 0.9532\n",
      "Epoch 8/12\n",
      "7291/7291 [==============================] - 9s 1ms/step - loss: 0.0557 - acc: 0.9827 - val_loss: 0.1630 - val_acc: 0.9571\n",
      "Epoch 9/12\n",
      "7291/7291 [==============================] - 9s 1ms/step - loss: 0.0522 - acc: 0.9835 - val_loss: 0.1594 - val_acc: 0.9581\n",
      "Epoch 10/12\n",
      "7291/7291 [==============================] - 9s 1ms/step - loss: 0.0400 - acc: 0.9886 - val_loss: 0.1668 - val_acc: 0.9591\n",
      "Epoch 11/12\n",
      "7291/7291 [==============================] - 10s 1ms/step - loss: 0.0362 - acc: 0.9881 - val_loss: 0.1649 - val_acc: 0.9616\n",
      "Epoch 12/12\n",
      "7291/7291 [==============================] - 10s 1ms/step - loss: 0.0410 - acc: 0.9867 - val_loss: 0.1574 - val_acc: 0.9611\n",
      "Test loss: 0.15738041021020766\n",
      "Test accuracy: 0.9611360240350865\n"
     ]
    }
   ],
   "source": [
    "# Task I –Neural Network Design\n",
    "\n",
    "# (1) Fully connected, where each input/neuron is connected to all the ne\n",
    "# urons in the next layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "task_I_1 = model.fit(x_train, y_train, batch_size=batch_size, \n",
    "                      epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# -------- Figures ---------------\n",
    "plt.plot(task_I_1.history['acc'])\n",
    "plt.plot(task_I_1.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('task_I_1_acc.jpg')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(task_I_1.history['loss'])\n",
    "plt.plot(task_I_1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('task_I_1_loss.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task I –Neural Network Design\n",
    "\n",
    "# (1) Fully connected, where each input/neuron is connected to all the ne\n",
    "# urons in the next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Locally connected  with  no  weights shared inthe\n",
    "# first  three  layers,  where  each  input/neuron  is \n",
    "# connected to the neurons in a local neighbor in the next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Locally connected with weights shared in the first three layers\n",
    "# (i.e., a convolutional neural network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
